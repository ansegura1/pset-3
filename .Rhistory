library(stopwords)
library(dplyr)
docs <- Corpus(VectorSource(Parrafos))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("spanish"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
set.seed(1234) # for reproducibility
wordcloud(words = df$word, freq = df$freq, min.freq = 1, max.words=100, random.order=FALSE, rot.per=0.25,colors=brewer.pal(8, "Dark2"))
png("output/nube_palabras.png")
install.packages("tm")
##################################Angela Segura Cod. 201619956   R version 4.1.3 ############################################
##Taller Pset_3####
###Crear directorio de trabajo##
dir.create("code") #Creamos carpeta llamada code, donde guardaremos el script
dir.create("output") #Creamos la carpeta output para los datos procesados
list.files() ## Revisamos con que carpetas estamos trabajando#
##El script lo guardamos manualmente en la carpeta de code con el nombre Scriptrespuesta##
###Instalar librerias##
require(pacman)
install.packages("tm")
install.packages("wordcloud")
p_load(tidyverse, rio,skimr,tmaptools, sf, leaflet, rvest, xml2, osmdata, ggsn, tm,wordcloud,dplyr) # Llamamos las librerias  necesarias para el taller##
#########################################1.Regresiones#######################################################
####################################################2. Datos espaciales######################################################
## 2.1  Descargar los datos##
available_features() %>% head(100)
available_tags("amenity") %>% head(20)
opq(bbox = getbb("Armenia Colombia")) # Vamos a obtener la caja de coordenada que contiene el polÃ­gono de Armenia##
## Datos de los restaurantes en Armenia
osm = opq(bbox = getbb("Armenia Colombia")) %>%
add_osm_feature(key="amenity" , value="restaurant") #En internet encontramos cÃ³mo encontrar los datos de los restaurantes en openstreetmap. (https://wiki.openstreetmap.org/wiki/Tag:amenity%3Drestaurant)
class(osm)
osm_sf = osm %>% osmdata_sf() ## extraer Simple Features Collection
osm_sf
restaurant = osm_sf$osm_points %>% select(osm_id,amenity)#Obtenemos el objeto
## Parques de Armenia
parques <- opq(bbox = getbb("Armenia Colombia")) %>%
add_osm_feature(key = "leisure", value = "park") %>%
osmdata_sf() %>% .$osm_polygons %>% select(osm_id,name)
## 2.2 Visualizar  los datos##
#restaurantes
leaflet() %>% addTiles() %>% addCircles(data=restaurant , col="red")
#parques
leaflet() %>% addTiles() %>% addPolygons(data=parques, col="blue")
#2.3 Geocodificar direcciones##
#Museo del oro Qumbaya
MOQ <- geocode_OSM("Museo del Oro Quimbaya, Armenia", as.sf=T)
#Pintar el punto del museo del Oro Quimbaya
leaflet() %>% addTiles() %>% addCircleMarkers(data=MOQ , col="yellow")
#2.4 Exportar mapa##
###################################3. Web-scraping y procesamiento de texto#####################################################
browseURL("https://es.wikipedia.org/wiki/Departamentos_de_Colombia") #Para el punto 3 vamos a usar la pagina de departamentos de Colombia
##3.1 Crear objeto html##
my_url = "https://es.wikipedia.org/wiki/Departamentos_de_Colombia" #Guardo la url de la pagina
browseURL(my_url)
my_html = read_html(my_url)#Guardo la Html
class(my_html) ## verificar que queda guardada   como un objeto xml_document#
##3.2  extraer el titulo de la pagina##
my_html %>% html_nodes(xpath = '//*[@id="firstHeading"]/span') %>% #En la pag le damos inspeccionar al elemento y posteriormente le damos copiar Xpath
html_text() #Visualizamos el elemento extraido
#3.3 Extraer la tabla que contiene los departamentos de Colombia y exportar
my_table = my_html %>% html_table() #Descargo todas las tablas de la pagina
View(my_table) #Observo cuantas filas y columnas tienen las tablas descargadas para encontrar la de departamentos
View(my_table[[4]]) #Verificamos que la tabla 5 corresponde a la tabla de departamentos
departamentos= my_table[[4]]
export(x=departamentos , file="output/tabla_departamento.xlsx")
#3.4 Extraer los parrafos del documento (elementos con etiqueta p) y generar nube de palabras##
Parrafos<- my_html %>% html_elements("p") %>% html_text() ### Ver los textos que estan con la etiqueta p
Parrafos
as.character(Parrafos)
docs <- Corpus(VectorSource(Parrafos))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("spanish"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
set.seed(1234) # for reproducibility
wordcloud(words = df$word, freq = df$freq, min.freq = 1, max.words=100, random.order=FALSE, rot.per=0.25,colors=brewer.pal(8, "Dark2"))
png("output/nube_palabras.png")
wordcloud(words = df$word, freq = df$freq, min.freq = 5, max.words=100, random.order=FALSE, rot.per=0.25,colors=brewer.pal(8, "Dark2"))
wordcloud(words = df$word, freq = df$freq, min.freq = 1, max.words=100, random.order=FALSE, rot.per=0.25,colors=brewer.pal(8, "Dark2"))
wordcloud(words = df$word, freq = df$freq, min.freq = 2, max.words=100, random.order=FALSE, rot.per=0.25,colors=brewer.pal(8, "Dark2"))
wordcloud(words = df$word, freq = df$freq, min.freq = 2, max.words=100, random.order=FALSE, rot.per=0.15,colors=brewer.pal(8, "Dark2"))
wordcloud(words = df$word, freq = df$freq, min.freq = 2, max.words=100, random.order=FALSE, rot.per=0.15,colors=brewer.pal(8, "Dark2")) scale=c(4, .5)
wordcloud(words = df$word, freq = df$freq, min.freq = 2, max.words=100, random.order=FALSE, rot.per=0.15,colors=brewer.pal(8, "Dark2") [3:5])
png("output/nube_palabras.png")
wordcloud(words = df$word, freq = df$freq, min.freq = 2, max.words=50, random.order=FALSE, rot.per=0.15,colors=brewer.pal(8, "Dark2") [3:5])
png("output/nube_palabras.png")
##################################Angela Segura Cod. 201619956   R version 4.1.3 ############################################
##Taller Pset_3####
###Crear directorio de trabajo##
dir.create("code") #Creamos carpeta llamada code, donde guardaremos el script
dir.create("output") #Creamos la carpeta output para los datos procesados
list.files() ## Revisamos con que carpetas estamos trabajando#
##El script lo guardamos manualmente en la carpeta de code con el nombre Scriptrespuesta##
###Instalar librerias##
require(pacman)
install.packages("tm") #Tm y wordcloud se descargan para crear la nube de palabras
install.packages("wordcloud")
p_load(tidyverse, rio,skimr,tmaptools, sf, leaflet, rvest, xml2, osmdata, ggsn, tm,wordcloud,dplyr) # Llamamos las librerias  necesarias para el taller##
#########################################1.Regresiones#######################################################
####################################################2. Datos espaciales######################################################
## 2.1  Descargar los datos##
available_features() %>% head(100)
available_tags("amenity") %>% head(20)
opq(bbox = getbb("Armenia Colombia")) # Vamos a obtener la caja de coordenada que contiene el polÃ­gono de Armenia##
## Datos de los restaurantes en Armenia
osm = opq(bbox = getbb("Armenia Colombia")) %>%
add_osm_feature(key="amenity" , value="restaurant") #En internet encontramos cÃ³mo encontrar los datos de los restaurantes en openstreetmap. (https://wiki.openstreetmap.org/wiki/Tag:amenity%3Drestaurant)
class(osm)
osm_sf = osm %>% osmdata_sf() ## extraer Simple Features Collection
osm_sf
restaurant = osm_sf$osm_points %>% select(osm_id,amenity)#Obtenemos el objeto
## Parques de Armenia
parques <- opq(bbox = getbb("Armenia Colombia")) %>%
add_osm_feature(key = "leisure", value = "park") %>%
osmdata_sf() %>% .$osm_polygons %>% select(osm_id,name)
## 2.2 Visualizar  los datos##
#restaurantes
leaflet() %>% addTiles() %>% addCircles(data=restaurant , col="red")
#parques
leaflet() %>% addTiles() %>% addPolygons(data=parques, col="blue")
#2.3 Geocodificar direcciones##
#Museo del oro Qumbaya
MOQ <- geocode_OSM("Museo del Oro Quimbaya, Armenia", as.sf=T)
#Pintar el punto del museo del Oro Quimbaya
leaflet() %>% addTiles() %>% addCircleMarkers(data=MOQ , col="yellow")
#2.4 Exportar mapa##
###################################3. Web-scraping y procesamiento de texto#####################################################
browseURL("https://es.wikipedia.org/wiki/Departamentos_de_Colombia") #Para el punto 3 vamos a usar la pagina de departamentos de Colombia
##3.1 Crear objeto html##
my_url = "https://es.wikipedia.org/wiki/Departamentos_de_Colombia" #Guardo la url de la pagina
browseURL(my_url)
my_html = read_html(my_url)#Guardo la Html
class(my_html) ## verificar que queda guardada   como un objeto xml_document#
##3.2  extraer el titulo de la pagina##
my_html %>% html_nodes(xpath = '//*[@id="firstHeading"]/span') %>% #En la pag le damos inspeccionar al elemento y posteriormente le damos copiar Xpath
html_text() #Visualizamos el elemento extraido
#3.3 Extraer la tabla que contiene los departamentos de Colombia y exportar
my_table = my_html %>% html_table() #Descargo todas las tablas de la pagina
View(my_table) #Observo cuantas filas y columnas tienen las tablas descargadas para encontrar la de departamentos
View(my_table[[4]]) #Verificamos que la tabla 5 corresponde a la tabla de departamentos
departamentos= my_table[[4]]
export(x=departamentos , file="output/tabla_departamento.xlsx")
#3.4 Extraer los parrafos del documento (elementos con etiqueta p) y generar nube de palabras##
Parrafos<- my_html %>% html_elements("p") %>% html_text() ### Ver los textos que estan con la etiqueta p
Parrafos
as.character(Parrafos)
docs <- Corpus(VectorSource(Parrafos))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("spanish"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
set.seed(1234) # for reproducibility
wordcloud(words = df$word, freq = df$freq, min.freq = 2, max.words=50, random.order=FALSE, rot.per=0.15,colors=brewer.pal(8, "Dark2") [3:5])
png("output/nube_palabras.png")
wordcloud(words = df$word, freq = df$freq, min.freq = 2, max.words=50, random.order=FALSE, rot.per=0.15,colors=brewer.pal(8, "Dark2") [2:5])
wordcloud(words = df$word, freq = df$freq, min.freq = 2, max.words=50, random.order=FALSE, rot.per=0.15,colors=brewer.pal(8, "Dark2") [2:3])
wordcloud(words = df$word, freq = df$freq, min.freq = 2, max.words=50, random.order=FALSE, rot.per=0.15,colors=brewer.pal(8, "Dark2") [2:6])
wordcloud(words = df$word, freq = df$freq, min.freq = 2, max.words=50, random.order=FALSE, rot.per=0.15,colors=brewer.pal(8, "Dark2") [1:5])
wordcloud(words = df$word, freq = df$freq, min.freq = 2, max.words=50, scale=c(2, .5), random.order=FALSE, rot.per=0.15,colors=brewer.pal(8, "Dark2") )
wordcloud(words = df$word, freq = df$freq, min.freq = 2, max.words=100, scale=c(4, .5), random.order=FALSE, rot.per=0.15,colors=brewer.pal(8, "Dark2") )
wordcloud(words = df$word, freq = df$freq, min.freq = 2, max.words=100, scale=c(3, .5), random.order=FALSE, rot.per=0.15,colors=brewer.pal(8, "Dark2") )
wordcloud(words = df$word, freq = df$freq, min.freq = 2, max.words=80, scale=c(3, .5), random.order=FALSE, rot.per=0.15,colors=brewer.pal(8, "Dark2") )
wordcloud(words = df$word, freq = df$freq, min.freq = 2, max.words=50, scale=c(3, .5), random.order=FALSE, rot.per=0.15,colors=brewer.pal(8, "Dark2") )
wordcloud(words = df$word, freq = df$freq, min.freq = 2, max.words=50, scale=c(2, .5), random.order=FALSE, rot.per=0.15,colors=brewer.pal(8, "Dark2") )
png("output/nube_palabras.png")
##################################Angela Segura Cod. 201619956   R version 4.1.3 ############################################
##Taller Pset_3####
###Crear directorio de trabajo##
dir.create("code") #Creamos carpeta llamada code, donde guardaremos el script
dir.create("output") #Creamos la carpeta output para los datos procesados
list.files() ## Revisamos con que carpetas estamos trabajando#
##El script lo guardamos manualmente en la carpeta de code con el nombre Scriptrespuesta##
###Instalar librerias##
require(pacman)
install.packages("tm") #Tm y wordcloud se descargan para crear la nube de palabras
install.packages("wordcloud")
p_load(tidyverse, rio,skimr,tmaptools, sf, leaflet, rvest, xml2, osmdata, ggsn, tm,wordcloud,dplyr) # Llamamos las librerias  necesarias para el taller##
#########################################1.Regresiones#######################################################
####################################################2. Datos espaciales######################################################
## 2.1  Descargar los datos##
available_features() %>% head(100)
available_tags("amenity") %>% head(20)
opq(bbox = getbb("Armenia Colombia")) # Vamos a obtener la caja de coordenada que contiene el polÃ­gono de Armenia##
## Datos de los restaurantes en Armenia
osm = opq(bbox = getbb("Armenia Colombia")) %>%
add_osm_feature(key="amenity" , value="restaurant") #En internet encontramos cÃ³mo encontrar los datos de los restaurantes en openstreetmap. (https://wiki.openstreetmap.org/wiki/Tag:amenity%3Drestaurant)
class(osm)
osm_sf = osm %>% osmdata_sf() ## extraer Simple Features Collection
osm_sf
restaurant = osm_sf$osm_points %>% select(osm_id,amenity)#Obtenemos el objeto
## Parques de Armenia
parques <- opq(bbox = getbb("Armenia Colombia")) %>%
add_osm_feature(key = "leisure", value = "park") %>%
osmdata_sf() %>% .$osm_polygons %>% select(osm_id,name)
## 2.2 Visualizar  los datos##
#restaurantes
leaflet() %>% addTiles() %>% addCircles(data=restaurant , col="red")
#parques
leaflet() %>% addTiles() %>% addPolygons(data=parques, col="blue")
#2.3 Geocodificar direcciones##
#Museo del oro Qumbaya
MOQ <- geocode_OSM("Museo del Oro Quimbaya, Armenia", as.sf=T)
#Pintar el punto del museo del Oro Quimbaya
leaflet() %>% addTiles() %>% addCircleMarkers(data=MOQ , col="yellow")
#2.4 Exportar mapa##
###################################3. Web-scraping y procesamiento de texto#####################################################
browseURL("https://es.wikipedia.org/wiki/Departamentos_de_Colombia") #Para el punto 3 vamos a usar la pagina de departamentos de Colombia
##3.1 Crear objeto html##
my_url = "https://es.wikipedia.org/wiki/Departamentos_de_Colombia" #Guardo la url de la pagina
browseURL(my_url)
my_html = read_html(my_url)#Guardo la Html
class(my_html) ## verificar que queda guardada   como un objeto xml_document#
##3.2  extraer el titulo de la pagina##
my_html %>% html_nodes(xpath = '//*[@id="firstHeading"]/span') %>% #En la pag le damos inspeccionar al elemento y posteriormente le damos copiar Xpath
html_text() #Visualizamos el elemento extraido
#3.3 Extraer la tabla que contiene los departamentos de Colombia y exportar
my_table = my_html %>% html_table() #Descargo todas las tablas de la pagina
View(my_table) #Observo cuantas filas y columnas tienen las tablas descargadas para encontrar la de departamentos
View(my_table[[4]]) #Verificamos que la tabla 5 corresponde a la tabla de departamentos
departamentos= my_table[[4]]
export(x=departamentos , file="output/tabla_departamento.xlsx")
#3.4 Extraer los parrafos del documento (elementos con etiqueta p) y generar nube de palabras##
Parrafos<- my_html %>% html_elements("p") %>% html_text() ### Ver los textos que estan con la etiqueta p
Parrafos
as.character(Parrafos)
docs <- Corpus(VectorSource(Parrafos))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("spanish"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
set.seed(1234) # for reproducibility
wordcloud(words = df$word, freq = df$freq, min.freq = 2, max.words=50, scale=c(2, .5), random.order=FALSE, rot.per=0.15,colors=brewer.pal(8, "Dark2") )
pdf("output/nube_palabras.pdf")
png("output/nube_palabras.png")
##################################Angela Segura Cod. 201619956   R version 4.1.3 ############################################
##Taller Pset_3####
###Crear directorio de trabajo##
dir.create("code") #Creamos carpeta llamada code, donde guardaremos el script
dir.create("output") #Creamos la carpeta output para los datos procesados
list.files() ## Revisamos con que carpetas estamos trabajando#
##El script lo guardamos manualmente en la carpeta de code con el nombre Scriptrespuesta##
###Instalar librerias##
require(pacman)
install.packages("tm") #Tm y wordcloud se descargan para crear la nube de palabras
install.packages("wordcloud")
p_load(tidyverse, rio,skimr,tmaptools, sf, leaflet, rvest, xml2, osmdata, ggsn, tm,wordcloud,dplyr) # Llamamos las librerias  necesarias para el taller##
#########################################1.Regresiones#######################################################
####################################################2. Datos espaciales######################################################
## 2.1  Descargar los datos##
available_features() %>% head(100)
available_tags("amenity") %>% head(20)
opq(bbox = getbb("Armenia Colombia")) # Vamos a obtener la caja de coordenada que contiene el polÃ­gono de Armenia##
## Datos de los restaurantes en Armenia
osm = opq(bbox = getbb("Armenia Colombia")) %>%
add_osm_feature(key="amenity" , value="restaurant") #En internet encontramos cÃ³mo encontrar los datos de los restaurantes en openstreetmap. (https://wiki.openstreetmap.org/wiki/Tag:amenity%3Drestaurant)
class(osm)
osm_sf = osm %>% osmdata_sf() ## extraer Simple Features Collection
##################################Angela Segura Cod. 201619956   R version 4.1.3 ############################################
##Taller Pset_3####
###Crear directorio de trabajo##
dir.create("code") #Creamos carpeta llamada code, donde guardaremos el script
dir.create("output") #Creamos la carpeta output para los datos procesados
list.files() ## Revisamos con que carpetas estamos trabajando#
##El script lo guardamos manualmente en la carpeta de code con el nombre Scriptrespuesta##
###Instalar librerias##
require(pacman)
install.packages("tm") #Tm y wordcloud se descargan para crear la nube de palabras
install.packages("wordcloud")
p_load(tidyverse, rio,skimr,tmaptools, sf, leaflet, rvest, xml2, osmdata, ggsn, tm,wordcloud,dplyr) # Llamamos las librerias  necesarias para el taller##
#########################################1.Regresiones#######################################################
####################################################2. Datos espaciales######################################################
## 2.1  Descargar los datos##
available_features() %>% head(100)
available_tags("amenity") %>% head(20)
opq(bbox = getbb("Armenia Colombia")) # Vamos a obtener la caja de coordenada que contiene el polÃ­gono de Armenia##
## Datos de los restaurantes en Armenia
osm = opq(bbox = getbb("Armenia Colombia")) %>%
add_osm_feature(key="amenity" , value="restaurant") #En internet encontramos cÃ³mo encontrar los datos de los restaurantes en openstreetmap. (https://wiki.openstreetmap.org/wiki/Tag:amenity%3Drestaurant)
class(osm)
osm_sf = osm %>% osmdata_sf() ## extraer Simple Features Collection
osm_sf
restaurant = osm_sf$osm_points %>% select(osm_id,amenity)#Obtenemos el objeto
## Parques de Armenia
parques <- opq(bbox = getbb("Armenia Colombia")) %>%
add_osm_feature(key = "leisure", value = "park") %>%
osmdata_sf() %>% .$osm_polygons %>% select(osm_id,name)
## 2.2 Visualizar  los datos##
#restaurantes
leaflet() %>% addTiles() %>% addCircles(data=restaurant , col="red")
#parques
leaflet() %>% addTiles() %>% addPolygons(data=parques, col="blue")
#2.3 Geocodificar direcciones##
#Museo del oro Qumbaya
MOQ <- geocode_OSM("Museo del Oro Quimbaya, Armenia", as.sf=T)
#Pintar el punto del museo del Oro Quimbaya
leaflet() %>% addTiles() %>% addCircleMarkers(data=MOQ , col="yellow")
#2.4 Exportar mapa##
###################################3. Web-scraping y procesamiento de texto#####################################################
browseURL("https://es.wikipedia.org/wiki/Departamentos_de_Colombia") #Para el punto 3 vamos a usar la pagina de departamentos de Colombia
##3.1 Crear objeto html##
my_url = "https://es.wikipedia.org/wiki/Departamentos_de_Colombia" #Guardo la url de la pagina
browseURL(my_url)
my_html = read_html(my_url)#Guardo la Html
class(my_html) ## verificar que queda guardada   como un objeto xml_document#
##3.2  extraer el titulo de la pagina##
my_html %>% html_nodes(xpath = '//*[@id="firstHeading"]/span') %>% #En la pag le damos inspeccionar al elemento y posteriormente le damos copiar Xpath
html_text() #Visualizamos el elemento extraido
#3.3 Extraer la tabla que contiene los departamentos de Colombia y exportar
my_table = my_html %>% html_table() #Descargo todas las tablas de la pagina
View(my_table) #Observo cuantas filas y columnas tienen las tablas descargadas para encontrar la de departamentos
View(my_table[[4]]) #Verificamos que la tabla 5 corresponde a la tabla de departamentos
departamentos= my_table[[4]]
export(x=departamentos , file="output/tabla_departamento.xlsx")
#3.4 Extraer los parrafos del documento (elementos con etiqueta p) y generar nube de palabras##
Parrafos<- my_html %>% html_elements("p") %>% html_text() ### Ver los textos que estan con la etiqueta p
Parrafos
as.character(Parrafos)
docs <- Corpus(VectorSource(Parrafos))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("spanish"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
set.seed(1234) # for reproducibility
wordcloud(words = df$word, freq = df$freq, min.freq = 2, max.words=50, scale=c(2, .5), random.order=FALSE, rot.per=0.15,colors=brewer.pal(8, "Dark2") )
pdf("./output/nube_palabras.pdf")
png("./output/nube_palabras.png")
##################################Angela Segura Cod. 201619956   R version 4.1.3 ############################################
##Taller Pset_3####
###Crear directorio de trabajo##
dir.create("code") #Creamos carpeta llamada code, donde guardaremos el script
dir.create("output") #Creamos la carpeta output para los datos procesados
list.files() ## Revisamos con que carpetas estamos trabajando#
##El script lo guardamos manualmente en la carpeta de code con el nombre Scriptrespuesta##
###Instalar librerias##
require(pacman)
install.packages("tm") #Tm y wordcloud se descargan para crear la nube de palabras
install.packages("wordcloud")
p_load(tidyverse, rio,skimr,tmaptools, sf, leaflet, rvest, xml2, osmdata, ggsn, tm,wordcloud,dplyr) # Llamamos las li
#########################################1.Regresiones#######################################################
####################################################2. Datos espaciales######################################################
## 2.1  Descargar los datos##
available_features() %>% head(100)
available_tags("amenity") %>% head(20)
opq(bbox = getbb("Armenia Colombia")) # Vamos a obtener la caja de coordenada que contiene el polÃ­gono de Armenia##
## Datos de los restaurantes en Armenia
osm = opq(bbox = getbb("Armenia Colombia")) %>%
add_osm_feature(key="amenity" , value="restaurant") #En internet encontramos cÃ³mo encontrar los datos de los restaurantes en openstreetmap. (https://wiki.openstreetmap.org/wiki/Tag:amenity%3Drestaurant)
class(osm)
osm_sf = osm %>% osmdata_sf() ## extraer Simple Features Collection
osm_sf
restaurant = osm_sf$osm_points %>% select(osm_id,amenity)#Obtenemos el objeto
## Parques de Armenia
parques <- opq(bbox = getbb("Armenia Colombia")) %>%
add_osm_feature(key = "leisure", value = "park") %>%
osmdata_sf() %>% .$osm_polygons %>% select(osm_id,name)
## 2.2 Visualizar  los datos##
#restaurantes
leaflet() %>% addTiles() %>% addCircles(data=restaurant , col="red")
#parques
leaflet() %>% addTiles() %>% addPolygons(data=parques, col="blue")
#2.3 Geocodificar direcciones##
#Museo del oro Qumbaya
MOQ <- geocode_OSM("Museo del Oro Quimbaya, Armenia", as.sf=T)
#Pintar el punto del museo del Oro Quimbaya
leaflet() %>% addTiles() %>% addCircleMarkers(data=MOQ , col="yellow")
#2.4 Exportar mapa##
###################################3. Web-scraping y procesamiento de texto#####################################################
browseURL("https://es.wikipedia.org/wiki/Departamentos_de_Colombia") #Para el punto 3 vamos a usar la pagina de departamentos de Colombia
##3.1 Crear objeto html##
my_url = "https://es.wikipedia.org/wiki/Departamentos_de_Colombia" #Guardo la url de la pagina
browseURL(my_url)
my_html = read_html(my_url)#Guardo la Html
class(my_html) ## verificar que queda guardada   como un objeto xml_document#
##3.2  extraer el titulo de la pagina##
my_html %>% html_nodes(xpath = '//*[@id="firstHeading"]/span') %>% #En la pag le damos inspeccionar al elemento y posteriormente le damos copiar Xpath
html_text() #Visualizamos el elemento extraido
#3.3 Extraer la tabla que contiene los departamentos de Colombia y exportar
my_table = my_html %>% html_table() #Descargo todas las tablas de la pagina
View(my_table) #Observo cuantas filas y columnas tienen las tablas descargadas para encontrar la de departamentos
View(my_table[[4]]) #Verificamos que la tabla 5 corresponde a la tabla de departamentos
departamentos= my_table[[4]]
