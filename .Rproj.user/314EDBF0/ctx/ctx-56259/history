add_osm_feature(key="amenity" , value="restaurant") #En internet encontramos cÃ³mo encontrar los datos de los restaurantes en openstreetmap. (https://wiki.openstreetmap.org/wiki/Tag:amenity%3Drestaurant)
class(osm)
osm_sf = osm %>% osmdata_sf() ## extraer Simple Features Collection
osm_sf
restaurant = osm_sf$osm_points %>% select(osm_id,amenity)#Obtenemos el objeto
## Parques de Armenia
parques <- opq(bbox = getbb("Armenia Colombia")) %>%
add_osm_feature(key = "leisure", value = "park") %>%
osmdata_sf() %>% .$osm_polygons %>% select(osm_id,name)
## 2.2 Visualizar  los datos##
#restaurantes
g1<-leaflet() %>% addTiles() %>% addCircles(data=restaurant , col="red")
#parques
g2<-leaflet() %>% addTiles() %>% addPolygons(data=parques, col="blue")
#2.3 Geocodificar direcciones##
#Museo del oro Qumbaya
MOQ <- geocode_OSM("Museo del Oro Quimbaya, Armenia", as.sf=T)
#Pintar el punto del museo del Oro Quimbaya
g3<-leaflet() %>% addTiles() %>% addCircleMarkers(data=MOQ , col="yellow")
g3<-leaflet() %>% addTiles() %>% addCircleMarkers(data=MOQ , col="yellow")
available_features() %>% head(100)
available_tags("amenity") %>% head(20)
opq(bbox = getbb("Armenia Colombia")) # Vamos a obtener la caja de coordenada que contiene el poligono de Armenia##
##Taller Pset_3####
###Crear directorio de trabajo##
dir.create("code") #Creamos carpeta llamada code, donde guardaremos el script
dir.create("output") #Creamos la carpeta output para los datos procesados
list.files() ## Revisamos con que carpetas estamos trabajando#
options(install.lock = FALSE)
##El script lo guardamos manualmente en la carpeta de code con el nombre Scriptrespuesta##
###Instalar librerias##
require(pacman)
#install.packages("rlang")
#install.packages("tm") #Tm y wordcloud se descargan para crear la nube de palabras
#install.packages("wordcloud")
p_load(tidyverse, rio,skimr,tmaptools, sf, leaflet, rvest, xml2, osmdata, ggsn, tm,wordcloud,dplyr,readr) # Llamamos las librerias  necesarias para el taller##
#########################################1.Regresiones#######################################################
#1.1 Estimaciones#
data_regresiones<-import(file ="input/data_regresiones.rds" ) #Importo la base de datos data_regresiones
summary(data_regresiones)
#Modelo 1
m1_price<-lm(price~dist_park+surface_total+luces_2021+rooms+bathrooms, data=data_regresiones)#Regresion 1 por la cual quiero determinar el precio
summary(m1_price)#Ver resultado de la regresion
#Modelo 2
m2_price<-lm(price~dist_park+surface_total+dist_cbd +rooms+bathrooms, data=data_regresiones)#Regresion 2 por la cual quiero determinar el precio
summary(m2_price)#Ver resultado de la regresion
#Modelo 3
m3_price<-lm(price~dist_park+surface_total +rooms+bathrooms+dist_cole, data=data_regresiones)#Regresion 3 por la cual quiero determinar el precio
summary(m3_price)#Ver resultado de la regresion
#1.2 Presentar resultados#
#Tabla para el modelo 1
var_names=names(coef(m1_price))
coef_vals=coef(m1_price)
dt1 <- data.frame(Modelo="m1_price",Variables=var_names, RegressionCoefficients=coef_vals)
#Tabla para el modelo 2
var_names=names(coef(m2_price))
coef_vals=coef(m1_price)
dt2 <- data.frame(Modelo="m2_price",Variables=var_names, RegressionCoefficients=coef_vals)
#Tabla para el modelo 3
var_names=names(coef(m3_price))
coef_vals=coef(m3_price)
dt3 <- data.frame(Modelo="m3_price",Variables=var_names, RegressionCoefficients=coef_vals)
#Conseguir tablas de los tres modelos
dt_resultados <- rbind(dt1,dt2,dt3)
#Exportar
export(x=dt_resultados, rowNames=FALSE , file="output/resultados_regresiones.xlsx")
available_features() %>% head(100)
available_tags("amenity") %>% head(20)
opq(bbox = getbb("Armenia Colombia")) # Vamos a obtener la caja de coordenada que contiene el poligono de Armenia##
## Datos de los restaurantes en Armenia
osm = opq(bbox = getbb("Armenia Colombia")) %>%
add_osm_feature(key="amenity" , value="restaurant") #En internet encontramos cÃ³mo encontrar los datos de los restaurantes en openstreetmap. (https://wiki.openstreetmap.org/wiki/Tag:amenity%3Drestaurant)
class(osm)
osm_sf = osm %>% osmdata_sf() ## extraer Simple Features Collection
osm_sf
restaurant = osm_sf$osm_points %>% select(osm_id,amenity)#Obtenemos el objeto
restaurant
parques <- opq(bbox = getbb("Armenia Colombia")) %>%
add_osm_feature(key = "leisure", value = "park") %>%
osmdata_sf() %>% .$osm_polygons %>% select(osm_id,name)
g1<-leaflet() %>% addTiles() %>% addCircles(data=restaurant , col="red")
leaflet() %>% addTiles() %>% addCircles(data=restaurant , col="red")
g2<-leaflet() %>% addTiles() %>% addPolygons(data=parques, col="blue")
g2
MOQ <- geocode_OSM("Museo del Oro Quimbaya, Armenia", as.sf=T)
g3<-leaflet() %>% addTiles() %>% addCircleMarkers(data=MOQ , col="yellow")
g3
browseURL("https://es.wikipedia.org/wiki/Departamentos_de_Colombia") #Para el punto 3 vamos a usar la pagina de departamentos de Colombia
my_url = "https://es.wikipedia.org/wiki/Departamentos_de_Colombia" #Guardo la url de la pagina
browseURL(my_url)
my_html = read_html(my_url)#Guardo la Html
class(my_html) ## verificar que queda guardada   como un objeto xml_document#
my_html %>% html_nodes(xpath = '//*[@id="firstHeading"]/span') %>% #En la pag le damos inspeccionar al elemento y posteriormente le damos copiar Xpath
html_text() #Visualizamos el elemento extraido
my_table = my_html %>% html_table() #Descargo todas las tablas de la pagina
View(my_table) #Observo cuantas filas y columnas tienen las tablas descargadas para encontrar la de departamentos
View(my_table[[4]]) #Verificamos que la tabla 5 corresponde a la tabla de departamentos
departamentos= my_table[[4]]
export(x=departamentos , file="output/tabla_departamento.xlsx")
Parrafos<- my_html %>% html_elements("p") %>% html_text() ### Ver los textos que estan con la etiqueta p
Parrafos
as.character(Parrafos)
docs <- Corpus(VectorSource(Parrafos))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("spanish"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
words <- sort(rowSums(matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
set.seed(1234) # for reproducibility
png("./output/nube_palabras.png") #Descargamos nuetra nube de palabras
wordcloud(words = df$word, freq = df$freq, min.freq = 2, max.words=50, scale=c(2, .5), random.order=FALSE, rot.per=0.15,colors=brewer.pal(8, "Dark2") )
docs <- Corpus(VectorSource(Parrafos))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("spanish"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
set.seed(1234) # for reproducibility
png("./output/nube_palabras.png") #Descargamos nuetra nube de palabras
wordcloud(words = df$word, freq = df$freq, min.freq = 2, max.words=50, scale=c(2, .5), random.order=FALSE, rot.per=0.15,colors=brewer.pal(8, "Dark2") )
##################################Angela Segura Cod. 201619956   R version 4.1.3 ############################################
##Taller Pset_3####
###Crear directorio de trabajo##
dir.create("code") #Creamos carpeta llamada code, donde guardaremos el script
dir.create("output") #Creamos la carpeta output para los datos procesados
list.files() ## Revisamos con que carpetas estamos trabajando#
options(install.lock = FALSE)
##El script lo guardamos manualmente en la carpeta de code con el nombre Scriptrespuesta##
###Instalar librerias##
require(pacman)
#install.packages("rlang")
#install.packages("tm") #Tm y wordcloud se descargan para crear la nube de palabras
#install.packages("wordcloud")
p_load(tidyverse, rio,skimr,tmaptools, sf, leaflet, rvest, xml2, osmdata, ggsn, tm,wordcloud,dplyr,readr) # Llamamos las librerias  necesarias para el taller##
#########################################1.Regresiones#######################################################
#1.1 Estimaciones#
data_regresiones<-import(file ="input/data_regresiones.rds" ) #Importo la base de datos data_regresiones
summary(data_regresiones)
#Modelo 1
m1_price<-lm(price~dist_park+surface_total+luces_2021+rooms+bathrooms, data=data_regresiones)#Regresion 1 por la cual quiero determinar el precio
summary(m1_price)#Ver resultado de la regresion
#Modelo 2
m2_price<-lm(price~dist_park+surface_total+dist_cbd +rooms+bathrooms, data=data_regresiones)#Regresion 2 por la cual quiero determinar el precio
summary(m2_price)#Ver resultado de la regresion
#Modelo 3
m3_price<-lm(price~dist_park+surface_total +rooms+bathrooms+dist_cole, data=data_regresiones)#Regresion 3 por la cual quiero determinar el precio
summary(m3_price)#Ver resultado de la regresion
#1.2 Presentar resultados#
#Tabla para el modelo 1
var_names=names(coef(m1_price))
coef_vals=coef(m1_price)
dt1 <- data.frame(Modelo="m1_price",Variables=var_names, RegressionCoefficients=coef_vals)
#Tabla para el modelo 2
var_names=names(coef(m2_price))
coef_vals=coef(m1_price)
dt2 <- data.frame(Modelo="m2_price",Variables=var_names, RegressionCoefficients=coef_vals)
#Tabla para el modelo 3
var_names=names(coef(m3_price))
coef_vals=coef(m3_price)
dt3 <- data.frame(Modelo="m3_price",Variables=var_names, RegressionCoefficients=coef_vals)
#Conseguir tablas de los tres modelos
dt_resultados <- rbind(dt1,dt2,dt3)
#Exportar
export(x=dt_resultados, rowNames=FALSE , file="output/resultados_regresiones.xlsx")
####################################################2. Datos espaciales######################################################
## 2.1  Descargar los datos##
available_features() %>% head(100)
available_tags("amenity") %>% head(20)
opq(bbox = getbb("Armenia Colombia")) # Vamos a obtener la caja de coordenada que contiene el poligono de Armenia##
## Datos de los restaurantes en Armenia
osm = opq(bbox = getbb("Armenia Colombia")) %>%
add_osm_feature(key="amenity" , value="restaurant") #En internet encontramos cÃ³mo encontrar los datos de los restaurantes en openstreetmap. (https://wiki.openstreetmap.org/wiki/Tag:amenity%3Drestaurant)
class(osm)
osm_sf = osm %>% osmdata_sf() ## extraer Simple Features Collection
osm_sf
restaurant = osm_sf$osm_points %>% select(osm_id,amenity)#Obtenemos el objeto
## Parques de Armenia
parques <- opq(bbox = getbb("Armenia Colombia")) %>%
add_osm_feature(key = "leisure", value = "park") %>%
osmdata_sf() %>% .$osm_polygons %>% select(osm_id,name)
## 2.2 Visualizar  los datos##
#restaurantes
g1<-leaflet() %>% addTiles() %>% addCircles(data=restaurant , col="red")
g1
#parques
g2<-leaflet() %>% addTiles() %>% addPolygons(data=parques, col="blue")
g2
#2.3 Geocodificar direcciones##
#Museo del oro Qumbaya
MOQ <- geocode_OSM("Museo del Oro Quimbaya, Armenia", as.sf=T)
#Pintar el punto del museo del Oro Quimbaya
g3<-leaflet() %>% addTiles() %>% addCircleMarkers(data=MOQ , col="yellow")
g3
###################################3. Web-scraping y procesamiento de texto#####################################################
browseURL("https://es.wikipedia.org/wiki/Departamentos_de_Colombia") #Para el punto 3 vamos a usar la pagina de departamentos de Colombia
##3.1 Crear objeto html##
my_url = "https://es.wikipedia.org/wiki/Departamentos_de_Colombia" #Guardo la url de la pagina
browseURL(my_url)
my_html = read_html(my_url)#Guardo la Html
class(my_html) ## verificar que queda guardada   como un objeto xml_document#
##3.2  extraer el titulo de la pagina##
my_html %>% html_nodes(xpath = '//*[@id="firstHeading"]/span') %>% #En la pag le damos inspeccionar al elemento y posteriormente le damos copiar Xpath
html_text() #Visualizamos el elemento extraido
#3.3 Extraer la tabla que contiene los departamentos de Colombia y exportar
my_table = my_html %>% html_table() #Descargo todas las tablas de la pagina
View(my_table) #Observo cuantas filas y columnas tienen las tablas descargadas para encontrar la de departamentos
View(my_table[[4]]) #Verificamos que la tabla 5 corresponde a la tabla de departamentos
departamentos= my_table[[4]]
export(x=departamentos , file="output/tabla_departamento.xlsx")
#3.4 Extraer los parrafos del documento (elementos con etiqueta p) y generar nube de palabras##
Parrafos<- my_html %>% html_elements("p") %>% html_text() ### Ver los textos que estan con la etiqueta p
Parrafos
as.character(Parrafos)
#Para crear las nubes de palabras use  la instrucciones de https://towardsdatascience.com/create-a-word-cloud-with-r-bde3e7422e8a
docs <- Corpus(VectorSource(Parrafos))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("spanish"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
set.seed(1234) # for reproducibility
png("./output/nube_palabras.png") #Descargamos nuetra nube de palabras
wordcloud(words = df$word, freq = df$freq, min.freq = 2, max.words=50, scale=c(2, .5), random.order=FALSE, rot.per=0.15,colors=brewer.pal(8, "Dark2") )
Parrafos<- my_html %>% html_elements("p") %>% html_text() ### Ver los textos que estan con la etiqueta p
Parrafos
as.character(Parrafos)
class(Parrafos)
docs <- Corpus(VectorSource(Parrafos))
docs
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("spanish"))
dtm <- TermDocumentMatrix(docs)
dtm
matrix <- as.matrix(dtm)
matrix
words <- sort(rowSums(matrix),decreasing=TRUE)
ords
words
df <- data.frame(word = names(words),freq=words)
df
set.seed(1234) # for reproducibility
wordcloud(words = df$word, freq = df$freq, min.freq = 2, max.words=50, scale=c(2, .5), random.order=FALSE, rot.per=0.15,colors=brewer.pal(8, "Dark2") )
wordcloud(words = df$word, freq = df$freq, min.freq = 2, max.words=50, scale=c(2, .5), random.order=FALSE, rot.per=0.15,colors=brewer.pal(8, "Dark2") )
df$word
df$freq
set.seed(1234) # for reproducibility
png("./output/nube_palabras.png")
wordcloud(words = df$word,
freq = df$freq,
min.freq = 3,
max.words=Inf,
scale=c(4, .5),
random.order=TRUE,
rot.per=0.1,
colors= "black",
random.color = FALSE,
ordered.colors = FALSE,
use.r.layout=FALSE,
fixed.asp=TRUE, ...)
png("./output/nube_palabras.png")
wordcloud(words = df$word,
freq = df$freq,
min.freq = 3,
max.words=Inf,
scale=c(4, .5),
random.order=TRUE,
rot.per=0.1,
colors= "black",
random.color = FALSE,
ordered.colors = FALSE,
use.r.layout=FALSE,
fixed.asp=TRUE)
wordcloud(words = df$word, freq = df$freq, min.freq = 1,           max.words=200, random.order=FALSE, rot.per=0.35,            colors=brewer.pal(8, "Dark2"))
wordcloud(words = df$word,
freq = df$freq,
min.freq = 1,
max.words=5,
random.order=FALSE,
rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = df$word,
freq = df$freq,
min.freq = 1,
max.words=5,
random.order=FALSE,
rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = df$word,
freq = df$freq,
min.freq = 1,
max.words=5,
random.order=FALSE,
scale=c(3.5,0.25)
rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = df$word,
freq = df$freq,
min.freq = 1,
max.words=5,
random.order=FALSE,
scale=c(3.5,0.25),
rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
library(wordcloud2)
set.seed(1234) # for reproducibility
png("./output/nube_palabras.png")
wordcloud2(data=df, size=1.6, color='random-dark')
df
wordcloud2(data=df, max.words=20,size=1.6, color='random-dark')
set.seed(1234) # for reproducibility
png("./output/nube_palabras.png")
wordcloud(words = df$word,
freq = df$freq,
min.freq = 3,
max.words=Inf,
scale=c(4, .5),
random.order=TRUE,
rot.per=0.1,
colors= "black",
random.color = FALSE,
ordered.colors = FALSE,
use.r.layout=FALSE,
fixed.asp=TRUE)
wordcloud(words = df$word,
freq = df$freq,
min.freq = 3,
max.words=50,
scale=c(4, .5),
random.order=TRUE,
rot.per=0.1,
colors= "black",
random.color = FALSE,
ordered.colors = FALSE,
use.r.layout=FALSE,
fixed.asp=TRUE)
wordcloud2(data = df,
figPath = "nube.png",
color = "skyblue",
shuffle = F,
size = 0.5,
ellipticity = 1.5)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = df$word, freq = df$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = df$word, freq = df$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud2(data = df,
figPath = "nube.png",
color = "skyblue",
shuffle = F,
size = 0.5,
ellipticity = 1.5)
wordcloud2(data=df, max.words=5,size=1.6, color='random-dark')
wordcloud2(data = df,
color = "skyblue",
shuffle = F,
size = 0.5,
ellipticity = 1.5)
g1
p23 <- plot_grid(g2, NULL, g3, rel_widths = c(1, -0.7, 1), nrow = 1)
library(cowplot)
p23 <- plot_grid(g2, NULL, g3, rel_widths = c(1, -0.7, 1), nrow = 1)
p23
p23
class(g1)
(osm)
osm_sf = osm %>% osmdata_sf() ## extraer Simple Features Collection
osm_sf
restaurant = osm_sf$osm_points %>% select(osm_id,amenity)#Obtenemos el objeto
## Parques de Armenia
parques <- opq(bbox = getbb("Armenia Colombia")) %>%
add_osm_feature(key = "leisure", value = "park") %>%
osmdata_sf() %>% .$osm_polygons %>% select(osm_id,name)
## 2.2 Visualizar  los datos##
#restaurantes
g1<-leaflet() %>% addTiles() %>% addCircles(data=restaurant , col="red")
##################################Angela Segura Cod. 201619956   R version 4.1.3 ############################################
##Taller Pset_3####
###Crear directorio de trabajo##
dir.create("code") #Creamos carpeta llamada code, donde guardaremos el script
dir.create("output") #Creamos la carpeta output para los datos procesados
list.files() ## Revisamos con que carpetas estamos trabajando#
options(install.lock = FALSE)
##El script lo guardamos manualmente en la carpeta de code con el nombre Scriptrespuesta##
###Instalar librerias##
require(pacman)
#install.packages("rlang")
#install.packages("tm") #Tm y wordcloud se descargan para crear la nube de palabras
#install.packages("wordcloud")
p_load(tidyverse, rio,skimr,tmaptools, sf, leaflet, rvest, xml2, osmdata, ggsn, tm,wordcloud,dplyr,readr) # Llamamos las librerias  necesarias para el taller##
#########################################1.Regresiones#######################################################
#1.1 Estimaciones#
data_regresiones<-import(file ="input/data_regresiones.rds" ) #Importo la base de datos data_regresiones
summary(data_regresiones)
#Modelo 1
m1_price<-lm(price~dist_park+surface_total+luces_2021+rooms+bathrooms, data=data_regresiones)#Regresion 1 por la cual quiero determinar el precio
summary(m1_price)#Ver resultado de la regresion
#Modelo 2
m2_price<-lm(price~dist_park+surface_total+dist_cbd +rooms+bathrooms, data=data_regresiones)#Regresion 2 por la cual quiero determinar el precio
summary(m2_price)#Ver resultado de la regresion
#Modelo 3
m3_price<-lm(price~dist_park+surface_total +rooms+bathrooms+dist_cole, data=data_regresiones)#Regresion 3 por la cual quiero determinar el precio
summary(m3_price)#Ver resultado de la regresion
#1.2 Presentar resultados#
#Tabla para el modelo 1
var_names=names(coef(m1_price))
coef_vals=coef(m1_price)
dt1 <- data.frame(Modelo="m1_price",Variables=var_names, RegressionCoefficients=coef_vals)
#Tabla para el modelo 2
var_names=names(coef(m2_price))
coef_vals=coef(m1_price)
dt2 <- data.frame(Modelo="m2_price",Variables=var_names, RegressionCoefficients=coef_vals)
#Tabla para el modelo 3
var_names=names(coef(m3_price))
coef_vals=coef(m3_price)
dt3 <- data.frame(Modelo="m3_price",Variables=var_names, RegressionCoefficients=coef_vals)
#Conseguir tablas de los tres modelos
dt_resultados <- rbind(dt1,dt2,dt3)
#Exportar
export(x=dt_resultados, rowNames=FALSE , file="output/resultados_regresiones.xlsx")
####################################################2. Datos espaciales######################################################
## 2.1  Descargar los datos##
available_features() %>% head(100)
available_tags("amenity") %>% head(20)
opq(bbox = getbb("Armenia Colombia")) # Vamos a obtener la caja de coordenada que contiene el poligono de Armenia##
## Datos de los restaurantes en Armenia
osm = opq(bbox = getbb("Armenia Colombia")) %>%
add_osm_feature(key="amenity" , value="restaurant") #En internet encontramos cÃ³mo encontrar los datos de los restaurantes en openstreetmap. (https://wiki.openstreetmap.org/wiki/Tag:amenity%3Drestaurant)
class(osm)
osm_sf = osm %>% osmdata_sf() ## extraer Simple Features Collection
osm_sf
restaurant = osm_sf$osm_points %>% select(osm_id,amenity)#Obtenemos el objeto
## Parques de Armenia
parques <- opq(bbox = getbb("Armenia Colombia")) %>%
add_osm_feature(key = "leisure", value = "park") %>%
osmdata_sf() %>% .$osm_polygons %>% select(osm_id,name)
## 2.2 Visualizar  los datos##
#restaurantes
g1<-leaflet() %>% addTiles() %>% addCircles(data=restaurant , col="red")
g1
#parques
g2<-leaflet() %>% addTiles() %>% addPolygons(data=parques, col="blue")
g2
#2.3 Geocodificar direcciones##
#Museo del oro Qumbaya
MOQ <- geocode_OSM("Museo del Oro Quimbaya, Armenia", as.sf=T)
#Pintar el punto del museo del Oro Quimbaya
g3<-leaflet() %>% addTiles() %>% addCircleMarkers(data=MOQ , col="yellow")
g3
#2.4 Exportar mapa##
###################################3. Web-scraping y procesamiento de texto#####################################################
browseURL("https://es.wikipedia.org/wiki/Departamentos_de_Colombia") #Para el punto 3 vamos a usar la pagina de departamentos de Colombia
##3.1 Crear objeto html##
my_url = "https://es.wikipedia.org/wiki/Departamentos_de_Colombia" #Guardo la url de la pagina
browseURL(my_url)
my_html = read_html(my_url)#Guardo la Html
class(my_html) ## verificar que queda guardada   como un objeto xml_document#
##3.2  extraer el titulo de la pagina##
my_html %>% html_nodes(xpath = '//*[@id="firstHeading"]/span') %>% #En la pag le damos inspeccionar al elemento y posteriormente le damos copiar Xpath
html_text() #Visualizamos el elemento extraido
#3.3 Extraer la tabla que contiene los departamentos de Colombia y exportar
my_table = my_html %>% html_table() #Descargo todas las tablas de la pagina
View(my_table) #Observo cuantas filas y columnas tienen las tablas descargadas para encontrar la de departamentos
View(my_table[[4]]) #Verificamos que la tabla 5 corresponde a la tabla de departamentos
departamentos= my_table[[4]]
export(x=departamentos , file="output/tabla_departamento.xlsx")
#3.4 Extraer los parrafos del documento (elementos con etiqueta p) y generar nube de palabras##
Parrafos<- my_html %>% html_elements("p") %>% html_text() ### Ver los textos que estan con la etiqueta p
Parrafos
as.character(Parrafos)
docs <- Corpus(VectorSource(Parrafos))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("spanish"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
set.seed(1234) # for reproducibility
png("./output/nube_palabras.png")
wordcloud(words = df$word, freq = df$freq, min.freq = 2, max.words=50, scale=c(2, .5), random.order=FALSE, rot.per=0.15,colors=brewer.pal(8, "Dark2") )
install.packages("tm") #Tm y wordcloud se descargan para crear la nube de palabras
install.packages("wordcloud")
